%--------------------------------------------------------------
\chapter*{Abstract}
% Stark verkürzte, überblicksartige Darstellung von Forschungsbedarf, Fragestellung, Methode, erwartetem Ergebnis und Nutzen.



One could regard the human voice as our most natural musical instrument. With this unique position in the musical domain and our innate familiarity with voice qualities, virtualizing the voice for an increasingly digitalized music production market has proven to be a challenging task. Since the early source-filter model \cite{fant_acoustic_1960}, singing voice synthesis has advanced far, with modern machine learning based methods like WaveNet \cite{oord_wavenet:_2016} or WGANSing \cite{chandna_wgansing:_2019} being capable of synthesizing sung phrases from text of phonetic sequences with a high accuracy. These methods achieve this only at the cost of a relatively low computational efficiency. For that reason, this thesis goes back to earlier approaches like extended source-filter models \cite{degottex_glottal_2010} to explore, how recent advances in machine learning can be incorporated with computationally deficient signal processing methods. To do so, we limit our scope on the synthesis of vowel synthesis. We aim to propose a model that is capable not only of capturing the original singers voice timbre qualities but also of blending between them to create new virtual singers.\\
After a brief introduction to singing voice synthesis and the state of research, this document presents three promising approaches to achieve the thesis goals as laid down above. MUSHRA \cite{itu-r_recommendation_bs.1534_method_2003} and subjective paired comparison tests are discussed as possible ways to evaluate the performance of a proposed method. The last two sections describe preparatory work that went into this proposal and the time plan for moving forward with this thesis.


%\chapter*{Zusammenfassung}
%Zusammenfassung in deutsch. Platzhalter.


